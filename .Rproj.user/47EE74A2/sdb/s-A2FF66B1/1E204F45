{
    "collab_server" : "",
    "contents" : "########### ~~~~~~~~~~~~~~~~~ ######## ~~~~~~~~~~~~~~~~~ ###########\n##                                                                ##\n##                  Coursera Data Science Capstone Project        ##\n##                  Marcia Lazo                                   ##\n##                                                                ##\n########### ~~~~~~~~~~~~~~~~~ ######## ~~~~~~~~~~~~~~~~~ ###########\n\nsuppressPackageStartupMessages(c(\n        library(shinythemes),\n        library(shiny),\n        library(tm),\n        library(stringr),\n        library(markdown),\n        library(stylo),\n        library(dplyr)))\n\n#The data was preprocessed using the code in prepareData.R, and then saved to file\n#It is being loaded here. I used 2% of all of the data as my sample and created the\n#n-grams from that 2%\nuniData <- load(file=\"./data/ngram_sorted_1.RData\")\nunigrams = gramfreq\nbiData <- load(file=\"./data/ngram_sorted_2.RData\")\nbigrams = gramfreq\ntriData <- load(file=\"./data/ngram_sorted_3.RData\")\ntrigrams = gramfreq\nquadData <- load(file=\"./data/ngram_sorted_4.RData\")\nquadgrams = gramfreq\n\n#This function is used to clean up the input text. The texts used to create the n-grams were all cleaned similarly ahead of time\n#so this text needs to be cleaned as well to make sure that a fair comparison of words is done\ncleanTheText<-function(text){\n        \n        clean <- tolower(text)\n        clean <- removePunctuation(clean)\n        clean <- removeNumbers(clean)\n        clean <- str_replace_all(clean, \"[^[:alnum:]]\", \" \")\n        clean <- stripWhitespace(clean)\n\n        return(clean)\n}\n\n#Using txt.to.word.ext from stylo. This package is good for English language tokenization\n#It splits the text into words and leaves contractions such as don't untouched. It also leaves\n#compound word constructs such as daughter-in-law intact as one \"word\"\ncleanInput <- function(text){\n        \n        input <- cleanTheText(text)\n        input <- txt.to.words.ext(input, language=\"English.all\", preserve.case = TRUE)\n        return(input)\n}\n\nPredNextTerm <- function(inStr)\n{\n  assign(\"mesg\", \"in PredNextTerm\", envir = .GlobalEnv)\n  #inStr <- cleanInput(inStr)\n  inStr <- unlist(strsplit(inStr, split=\" \"));\n  inStrLen <- length(inStr);\n  \n  nxtTermFound <- FALSE;\n  #predNxtTerm <- as.character(NULL);\n  predNxtTerm <- as.character(\"Nothing entered yet\");\n  if (inStrLen >= 3 & !nxtTermFound)\n  {\n    # Take the input string and tokenize it, separating tokesn by a single space \n    inStr1 <- paste(inStr[(inStrLen-2):inStrLen], collapse=\" \");\n    # Subset the Four Gram data frame \n    searchStr <- paste(\"^\",inStr1, sep = \"\");\n    quadgramsTemp <- subset(quadgrams, grepl(searchStr, quadgrams[,1]))\n    #quadgramsTemp <- quadgrams[grep (searchStr, quadgrams[,1]), ];\n    #print(quadgramsTemp)\n    # Check to see if any matching record returned\n    if ( length(quadgramsTemp[, 1]) > 1 )\n    {\n      predNxtTerm <- quadgramsTemp[1,1];\n      nxtTermFound <- TRUE;\n    }\n    quadgramsTemp <- NULL;\n  }\n  if (inStrLen >= 2 & !nxtTermFound){\n    inStr1 <- paste(inStr[(inStrLen-1):inStrLen], collapse=\" \");\n    # Subset the Four Gram data frame \n    searchStr <- paste(\"^\",inStr1, sep = \"\"); \n    trigramsTemp <- subset(trigrams, grepl(searchStr, trigrams[,1]))\n    #print(trigramsTemp[1][1])\n    # Check to see if any matching record returned\n    if ( length(trigramsTemp[, 1]) > 1 )\n    {\n      predNxtTerm <- trigramsTemp[1,1];\n      nxtTermFound <- TRUE;\n    }\n    trigramsTemp <- NULL;\n  }\n  if (inStrLen >= 1 & !nxtTermFound) {\n    inputStr <- inStr[inStrLen]\n    \n    # search and ubset the bigram data frame\n    searchStr <- paste(\"^\", inputStr, sep = \"\")\n    bigramsTemp <- subset(bigrams, grepl(searchStr, bigrams[, 1]))\n    #print(bigramsTemp)\n    # Check to see if any matching record returned\n    if (length(bigramsTemp[, 1]) > 1)\n    {\n      predNxtTerm <- bigramsTemp[1, 1]\n      nxtTermFound <- TRUE\n    }\n    bigramsTemp <- NULL\n  }\n  if(!nxtTermFound & inStrLen > 0)\n  {\n    predNxtTerm <- unigrams[1,1];\n  }\n  \n  #nextTerm <- word(predNxtTerm, -1);\n  print(predNxtTerm)\n  if (inStrLen > 0){\n    nextTerm <- word(predNxtTerm, -1);\n    return(nextTerm)\n  } else {\n    nextTerm <- \"\";\n    return(nextTerm);\n  }\n}",
    "created" : 1475637909769.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3957501196",
    "id" : "1E204F45",
    "lastKnownWriteTime" : 1476037723,
    "last_content_update" : 1476037723731,
    "path" : "~/Documents/DataScienceCoursera/MLazoCapstoneFinalProj/cleanAndPredict.R",
    "project_path" : "cleanAndPredict.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}