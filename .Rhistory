shiny::runApp()
runApp()
wordPrediction <- as.character(quadData[quadData$unigram==textInput[1] &
runApp()
;
runApp()
runApp()
runApp()
################# ~~~~~~~~~~~~~~~~~ ######## ~~~~~~~~~~~~~~~~~ #################
shiny::runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp('~/Documents/DataScienceCoursera/MLazoCapstoneBackupFinal')
runApp('~/Documents/DataScienceCoursera/MLazoCapstoneBackupFinal')
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
suppressPackageStartupMessages(c(
library(shinythemes),
library(shiny),
library(tm),
library(stringr),
library(markdown),
library(stylo)))
quadData <- readRDS(file="./data/quadgrams.RData")
triData <- readRDS(file="./data/triData.RData")
biData <- readRDS(file="./data/biData.RData")
head(biData)
head(triData, n =20)
head(quadData, n =20)
library(quanteda)
install.packages("quanteda")
library(quanteda)
install.packages("quanteda")
install.packages("Rweka")
install.packages("RWeka")
library(RWeka)
library(RWekajars)
lines <- readLines(fopen, warn=FALSE)
datafolder = './en_US'
flist <- list.files(path=datafolder, recursive=T, pattern=".*en_.*.txt")
l <- lapply(paste(datafolder, flist, sep="/"), function(f) {
fsize <- file.info(f)$size/1e6
fopen <- file(f, open="r")
lines <- readLines(fopen, warn=FALSE)
nchars <- lapply(lines, type="chars", nchar)
maxchars <- which.max(nchars)
nwords <- sum(sapply(strsplit(lines, "\\s+"), length))
close(fopen)
return(c(f, format(round(fsize, 2), nsmall=2), length(lines), maxchars, nwords))
})
df <- data.frame(matrix(unlist(l), nrow=length(l), byrow=T))
colnames(df) <- c("file", "size(MB)", "num.of.lines", "longest.line", "num.of.words")
df
blogs <- readLines("en_US/en_US.blogs.txt", warn=FALSE)
news <- readLines("en_US/en_US.news.txt", warn=FALSE)
twitter <- readLines("en_US/en_US.twitter.txt", warn=FALSE)
lb = length(blogs)
ln = length(news)
lt = length(twitter)
blogSamples <- blogs[sample(1:lb,0.05*lb)]
remove(blogs)
newsSamples <- news[sample(1:ln,.05*ln)]
remove(news)
twitterSamples <- twitter[sample(1:lt,.05*lt)]
remove(twitter)
mysamples <- list(blogSamples, newsSamples, twitterSamples)
